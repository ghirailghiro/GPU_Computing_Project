{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHjtWjHQ1jCfbbVfxTGXXM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghirailghiro/GPU_Computing_Project/blob/1-start-exploration-and-first-setup/Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EUv_2WqR1oaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac3eac2-b486-446f-8af9-002f8849ec8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-zq5754fb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-zq5754fb\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n",
            "Thu Dec 14 20:34:32 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plugin for cpp sintax highlighting\n",
        "\n",
        "!wget -O cpp_plugin.py https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n",
        "%load_ext cpp_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pEp9bNQ9ysq",
        "outputId": "01f0dd3f-5484-4df2-b2b1-35dd4b2e3a40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-14 20:34:32--  https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n",
            "Resolving gist.github.com (gist.github.com)... 20.205.243.166\n",
            "Connecting to gist.github.com (gist.github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://gist.githubusercontent.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py [following]\n",
            "--2023-12-14 20:34:32--  https://gist.githubusercontent.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2730 (2.7K) [text/plain]\n",
            "Saving to: ‘cpp_plugin.py’\n",
            "\n",
            "\rcpp_plugin.py         0%[                    ]       0  --.-KB/s               \rcpp_plugin.py       100%[===================>]   2.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-14 20:34:32 (47.7 MB/s) - ‘cpp_plugin.py’ saved [2730/2730]\n",
            "\n",
            "The cpp_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext cpp_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title working directory: **/content/hello**\n",
        "%mkdir -p hello\n",
        "%ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG3leFPZ94BF",
        "outputId": "e80638dc-1687-4342-c1d0-7c642857d4b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 32\n",
            "drwxr-xr-x 1 root root 4096 Dec 14 20:33 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Dec 14 20:31 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4096 Dec 13 14:22 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root 2730 Dec 14 20:34 cpp_plugin.py\n",
            "drwxr-xr-x 2 root root 4096 Dec 14 20:33 \u001b[01;34mhello\u001b[0m/\n",
            "drwxr-xr-x 2 root root 4096 Dec 14 20:33 \u001b[01;34m__pycache__\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Dec 13 14:22 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 2 root root 4096 Dec 14 20:33 \u001b[01;34msrc\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name hello.cu\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void helloFromGPU (void) {\n",
        "  int tID = threadIdx.x;\n",
        "  printf(\"Hello World from GPU (I'am thread %d)!\\n\", tID);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  //# hello from GPU\n",
        "  cout << \"Hello World from CPU!\" << endl;\n",
        "  cudaSetDevice(1);\n",
        "  helloFromGPU <<<1, 10>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CGzOzeM0-AYN",
        "outputId": "c8dfb011-965b-40b3-9852-6b7d313e0629"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/hello.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc src/hello.cu -o hello1\n",
        "ls -la hello1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaCOAEsS-FJk",
        "outputId": "006da5cc-67da-4724-a368-165c25e26212"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 968360 Dec 14 20:35 hello1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "./hello1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNFX_1UlC1GL",
        "outputId": "c5b990fd-14b5-421c-f24c-5f9d9ce39de1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from GPU (I'am thread 0)!\n",
            "Hello World from GPU (I'am thread 1)!\n",
            "Hello World from GPU (I'am thread 2)!\n",
            "Hello World from GPU (I'am thread 3)!\n",
            "Hello World from GPU (I'am thread 4)!\n",
            "Hello World from GPU (I'am thread 5)!\n",
            "Hello World from GPU (I'am thread 6)!\n",
            "Hello World from GPU (I'am thread 7)!\n",
            "Hello World from GPU (I'am thread 8)!\n",
            "Hello World from GPU (I'am thread 9)!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}